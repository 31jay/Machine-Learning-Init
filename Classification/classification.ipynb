{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The iris data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                 5.1               3.5                1.4               0.2   \n",
       "1                 4.9               3.0                1.4               0.2   \n",
       "2                 4.7               3.2                1.3               0.2   \n",
       "3                 4.6               3.1                1.5               0.2   \n",
       "4                 5.0               3.6                1.4               0.2   \n",
       "5                 5.4               3.9                1.7               0.4   \n",
       "6                 4.6               3.4                1.4               0.3   \n",
       "7                 5.0               3.4                1.5               0.2   \n",
       "8                 4.4               2.9                1.4               0.2   \n",
       "9                 4.9               3.1                1.5               0.1   \n",
       "10                5.4               3.7                1.5               0.2   \n",
       "11                4.8               3.4                1.6               0.2   \n",
       "12                4.8               3.0                1.4               0.1   \n",
       "13                4.3               3.0                1.1               0.1   \n",
       "14                5.8               4.0                1.2               0.2   \n",
       "15                5.7               4.4                1.5               0.4   \n",
       "16                5.4               3.9                1.3               0.4   \n",
       "17                5.1               3.5                1.4               0.3   \n",
       "18                5.7               3.8                1.7               0.3   \n",
       "19                5.1               3.8                1.5               0.3   \n",
       "20                5.4               3.4                1.7               0.2   \n",
       "21                5.1               3.7                1.5               0.4   \n",
       "22                4.6               3.6                1.0               0.2   \n",
       "23                5.1               3.3                1.7               0.5   \n",
       "24                4.8               3.4                1.9               0.2   \n",
       "\n",
       "    target species  \n",
       "0        0  setosa  \n",
       "1        0  setosa  \n",
       "2        0  setosa  \n",
       "3        0  setosa  \n",
       "4        0  setosa  \n",
       "5        0  setosa  \n",
       "6        0  setosa  \n",
       "7        0  setosa  \n",
       "8        0  setosa  \n",
       "9        0  setosa  \n",
       "10       0  setosa  \n",
       "11       0  setosa  \n",
       "12       0  setosa  \n",
       "13       0  setosa  \n",
       "14       0  setosa  \n",
       "15       0  setosa  \n",
       "16       0  setosa  \n",
       "17       0  setosa  \n",
       "18       0  setosa  \n",
       "19       0  setosa  \n",
       "20       0  setosa  \n",
       "21       0  setosa  \n",
       "22       0  setosa  \n",
       "23       0  setosa  \n",
       "24       0  setosa  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "df=pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target']=iris.target\n",
    "df['species']=df['target'].apply(lambda x: iris.target_names[x])\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled X_Train: [[-1.47393679  1.20365799 -1.56253475 -1.31260282]\n",
      " [-0.13307079  2.99237573 -1.27600637 -1.04563275]\n",
      " [ 1.08589829  0.08570939  0.38585821  0.28921757]\n",
      " [-1.23014297  0.75647855 -1.2187007  -1.31260282]\n",
      " [-1.7177306   0.30929911 -1.39061772 -1.31260282]\n",
      " [ 0.59831066 -1.25582892  0.72969227  0.95664273]\n",
      " [ 0.72020757  0.30929911  0.44316389  0.4227026 ]\n",
      " [-0.74255534  0.98006827 -1.27600637 -1.31260282]\n",
      " [-0.98634915  1.20365799 -1.33331205 -1.31260282]\n",
      " [-0.74255534  2.32160658 -1.27600637 -1.44608785]\n",
      " [-0.01117388 -0.80864948  0.78699794  0.95664273]\n",
      " [ 0.23261993  0.75647855  0.44316389  0.55618763]\n",
      " [ 1.08589829  0.08570939  0.55777524  0.4227026 ]\n",
      " [-0.49876152  1.87442714 -1.39061772 -1.04563275]\n",
      " [-0.49876152  1.4272477  -1.27600637 -1.31260282]\n",
      " [-0.37686461 -1.47941864 -0.01528151 -0.24472256]\n",
      " [ 0.59831066 -0.58505976  0.78699794  0.4227026 ]\n",
      " [ 0.72020757  0.08570939  1.01622064  0.8231577 ]\n",
      " [ 0.96400139 -0.13788033  0.38585821  0.28921757]\n",
      " [ 1.69538284  1.20365799  1.3600547   1.75755292]\n",
      " [-0.13307079 -0.36147005  0.27124686  0.15573254]\n",
      " [ 2.18297047 -0.13788033  1.64658307  1.22361279]\n",
      " [-0.2549677  -0.13788033  0.44316389  0.4227026 ]\n",
      " [-0.86445224  0.98006827 -1.33331205 -1.31260282]\n",
      " [ 2.30486738 -0.58505976  1.70388875  1.09012776]\n",
      " [-0.01117388 -0.80864948  0.21394119 -0.24472256]\n",
      " [-0.74255534  0.75647855 -1.33331205 -1.31260282]\n",
      " [-0.98634915  0.98006827 -1.39061772 -1.17911778]\n",
      " [-0.86445224  1.65083742 -1.04678367 -1.04563275]\n",
      " [-0.98634915 -2.37377751 -0.12989286 -0.24472256]\n",
      " [ 0.59831066 -0.80864948  0.67238659  0.8231577 ]\n",
      " [-1.23014297  0.75647855 -1.04678367 -1.31260282]\n",
      " [-0.98634915 -0.13788033 -1.2187007  -1.31260282]\n",
      " [-0.86445224  0.53288883 -1.16139502 -0.91214772]\n",
      " [-0.2549677  -0.80864948  0.27124686  0.15573254]\n",
      " [-0.86445224  0.75647855 -1.27600637 -1.31260282]\n",
      " [-0.13307079 -0.13788033  0.27124686  0.02224751]\n",
      " [ 2.30486738  1.65083742  1.70388875  1.35709783]\n",
      " [-1.47393679  0.30929911 -1.33331205 -1.31260282]\n",
      " [ 0.47641375 -0.36147005  0.32855254  0.15573254]\n",
      " [-0.13307079 -1.25582892  0.72969227  1.09012776]\n",
      " [-0.37686461  2.5451963  -1.33331205 -1.31260282]\n",
      " [ 0.23261993 -0.13788033  0.61508092  0.8231577 ]\n",
      " [-0.01117388 -0.80864948  0.78699794  0.95664273]\n",
      " [ 0.23261993 -1.92659808  0.15663551 -0.24472256]\n",
      " [-0.49876152 -0.13788033  0.44316389  0.4227026 ]\n",
      " [ 0.47641375  0.75647855  0.95891497  1.49058286]\n",
      " [-0.37686461 -1.70300836  0.15663551  0.15573254]\n",
      " [-0.49876152  1.87442714 -1.16139502 -1.04563275]\n",
      " [-0.98634915 -1.70300836 -0.24450422 -0.24472256]\n",
      " [ 0.72020757 -0.80864948  0.90160929  0.95664273]\n",
      " [-0.98634915  0.53288883 -1.33331205 -1.31260282]\n",
      " [-0.98634915  0.30929911 -1.4479234  -1.31260282]\n",
      " [-0.37686461 -1.47941864  0.04202416 -0.11123753]\n",
      " [ 1.08589829 -0.13788033  0.72969227  0.68967267]\n",
      " [-1.10824606  0.08570939 -1.27600637 -1.31260282]\n",
      " [-0.01117388 -0.58505976  0.78699794  1.62406789]\n",
      " [-0.98634915  0.75647855 -1.27600637 -1.31260282]\n",
      " [-0.98634915  0.98006827 -1.2187007  -0.77866269]\n",
      " [ 0.11072303  0.30929911  0.61508092  0.8231577 ]\n",
      " [-0.86445224 -1.25582892 -0.41642124 -0.11123753]\n",
      " [ 1.32969211  0.30929911  1.130832    1.49058286]\n",
      " [ 0.23261993 -0.80864948  0.78699794  0.55618763]\n",
      " [ 0.35451684 -1.0322392   1.07352632  0.28921757]\n",
      " [ 2.30486738 -0.13788033  1.3600547   1.49058286]\n",
      " [-0.37686461 -1.25582892  0.15663551  0.15573254]\n",
      " [-1.7177306  -0.36147005 -1.33331205 -1.31260282]\n",
      " [-1.83962751 -0.13788033 -1.50522907 -1.44608785]\n",
      " [ 0.23261993 -1.92659808  0.72969227  0.4227026 ]\n",
      " [ 1.69538284  0.30929911  1.30274902  0.8231577 ]\n",
      " [-1.47393679  0.08570939 -1.27600637 -1.31260282]\n",
      " [-0.86445224  0.98006827 -1.33331205 -1.17911778]\n",
      " [-1.7177306  -0.13788033 -1.39061772 -1.31260282]\n",
      " [ 0.59831066 -1.25582892  0.67238659  0.4227026 ]\n",
      " [ 0.59831066  0.75647855  1.07352632  1.62406789]\n",
      " [-1.47393679  0.75647855 -1.33331205 -1.17911778]\n",
      " [ 1.2077952  -0.13788033  1.01622064  1.22361279]\n",
      " [ 0.59831066  0.53288883  1.30274902  1.75755292]\n",
      " [-1.35203988  0.30929911 -1.39061772 -1.31260282]\n",
      " [ 0.35451684 -0.36147005  0.55777524  0.28921757]\n",
      " [ 0.84210448 -0.58505976  0.50046957  0.4227026 ]\n",
      " [ 0.47641375 -0.58505976  0.61508092  0.8231577 ]\n",
      " [ 1.45158902  0.30929911  0.55777524  0.28921757]\n",
      " [ 0.72020757  0.30929911  0.90160929  1.49058286]\n",
      " [-0.86445224  1.65083742 -1.2187007  -1.31260282]\n",
      " [ 1.32969211  0.08570939  0.95891497  1.22361279]\n",
      " [ 0.11072303 -0.13788033  0.27124686  0.4227026 ]\n",
      " [ 0.84210448 -0.13788033  0.84430362  1.09012776]\n",
      " [-0.13307079 -1.0322392  -0.12989286 -0.24472256]\n",
      " [-0.74255534 -0.80864948  0.09932984  0.28921757]\n",
      " [ 0.35451684 -0.13788033  0.50046957  0.28921757]\n",
      " [-1.5958337  -1.70300836 -1.39061772 -1.17911778]\n",
      " [ 0.96400139 -0.36147005  0.50046957  0.15573254]\n",
      " [-0.37686461 -1.0322392   0.38585821  0.02224751]\n",
      " [-0.62065843  1.4272477  -1.27600637 -1.31260282]\n",
      " [-0.2549677  -0.13788033  0.21394119  0.15573254]\n",
      " [ 1.81727975 -0.36147005  1.47466605  0.8231577 ]\n",
      " [ 1.08589829  0.53288883  1.130832    1.22361279]\n",
      " [-0.86445224  1.4272477  -1.27600637 -1.04563275]\n",
      " [-1.10824606 -1.47941864 -0.24450422 -0.24472256]\n",
      " [ 1.08589829  0.53288883  1.130832    1.75755292]\n",
      " [ 1.69538284 -0.13788033  1.18813767  0.55618763]\n",
      " [-1.10824606  1.20365799 -1.33331205 -1.44608785]\n",
      " [ 1.08589829  0.08570939  1.07352632  1.62406789]\n",
      " [-1.10824606 -0.13788033 -1.33331205 -1.31260282]\n",
      " [ 1.32969211  0.08570939  0.67238659  0.4227026 ]\n",
      " [ 1.93917666 -0.58505976  1.3600547   0.95664273]\n",
      " [ 0.59831066 -0.36147005  1.07352632  0.8231577 ]\n",
      " [-0.13307079 -0.58505976  0.21394119  0.15573254]\n",
      " [ 0.84210448 -0.13788033  1.01622064  0.8231577 ]\n",
      " [ 0.59831066 -1.70300836  0.38585821  0.15573254]\n",
      " [ 0.72020757 -0.36147005  0.32855254  0.15573254]\n",
      " [-0.2549677  -0.58505976  0.67238659  1.09012776]\n",
      " [ 0.11072303 -0.13788033  0.78699794  0.8231577 ]\n",
      " [-0.49876152  0.75647855 -1.16139502 -1.31260282]\n",
      " [ 0.35451684 -0.58505976  0.15663551  0.15573254]\n",
      " [-1.10824606 -1.25582892  0.44316389  0.68967267]\n",
      " [-0.01117388  2.09801686 -1.4479234  -1.31260282]\n",
      " [-0.01117388 -1.0322392   0.15663551  0.02224751]\n",
      " [ 1.57348593 -0.13788033  1.24544335  1.22361279]]\n",
      "[np.str_('setosa') np.str_('setosa') np.str_('versicolor')\n",
      " np.str_('setosa') np.str_('setosa') np.str_('virginica')\n",
      " np.str_('versicolor') np.str_('setosa') np.str_('setosa')\n",
      " np.str_('setosa') np.str_('virginica') np.str_('versicolor')\n",
      " np.str_('versicolor') np.str_('setosa') np.str_('setosa')\n",
      " np.str_('versicolor') np.str_('versicolor') np.str_('virginica')\n",
      " np.str_('versicolor') np.str_('virginica') np.str_('versicolor')\n",
      " np.str_('virginica') np.str_('versicolor') np.str_('setosa')\n",
      " np.str_('virginica') np.str_('versicolor') np.str_('setosa')\n",
      " np.str_('setosa') np.str_('setosa') np.str_('versicolor')\n",
      " np.str_('virginica') np.str_('setosa') np.str_('setosa')\n",
      " np.str_('setosa') np.str_('versicolor') np.str_('setosa')\n",
      " np.str_('versicolor') np.str_('virginica') np.str_('setosa')\n",
      " np.str_('versicolor') np.str_('virginica') np.str_('setosa')\n",
      " np.str_('virginica') np.str_('virginica') np.str_('versicolor')\n",
      " np.str_('versicolor') np.str_('virginica') np.str_('versicolor')\n",
      " np.str_('setosa') np.str_('versicolor') np.str_('virginica')\n",
      " np.str_('setosa') np.str_('setosa') np.str_('versicolor')\n",
      " np.str_('virginica') np.str_('setosa') np.str_('virginica')\n",
      " np.str_('setosa') np.str_('setosa') np.str_('virginica')\n",
      " np.str_('versicolor') np.str_('virginica') np.str_('virginica')\n",
      " np.str_('virginica') np.str_('virginica') np.str_('versicolor')\n",
      " np.str_('setosa') np.str_('setosa') np.str_('virginica')\n",
      " np.str_('virginica') np.str_('setosa') np.str_('setosa')\n",
      " np.str_('setosa') np.str_('versicolor') np.str_('virginica')\n",
      " np.str_('setosa') np.str_('virginica') np.str_('virginica')\n",
      " np.str_('setosa') np.str_('versicolor') np.str_('versicolor')\n",
      " np.str_('virginica') np.str_('versicolor') np.str_('virginica')\n",
      " np.str_('setosa') np.str_('virginica') np.str_('versicolor')\n",
      " np.str_('virginica') np.str_('versicolor') np.str_('versicolor')\n",
      " np.str_('versicolor') np.str_('setosa') np.str_('versicolor')\n",
      " np.str_('versicolor') np.str_('setosa') np.str_('versicolor')\n",
      " np.str_('virginica') np.str_('virginica') np.str_('setosa')\n",
      " np.str_('versicolor') np.str_('virginica') np.str_('virginica')\n",
      " np.str_('setosa') np.str_('virginica') np.str_('setosa')\n",
      " np.str_('versicolor') np.str_('virginica') np.str_('virginica')\n",
      " np.str_('versicolor') np.str_('virginica') np.str_('versicolor')\n",
      " np.str_('versicolor') np.str_('virginica') np.str_('virginica')\n",
      " np.str_('setosa') np.str_('versicolor') np.str_('virginica')\n",
      " np.str_('setosa') np.str_('versicolor') np.str_('virginica')] 73     versicolor\n",
      "18         setosa\n",
      "118     virginica\n",
      "78     versicolor\n",
      "76     versicolor\n",
      "31         setosa\n",
      "64     versicolor\n",
      "141     virginica\n",
      "68     versicolor\n",
      "82     versicolor\n",
      "110     virginica\n",
      "12         setosa\n",
      "36         setosa\n",
      "9          setosa\n",
      "19         setosa\n",
      "56     versicolor\n",
      "104     virginica\n",
      "69     versicolor\n",
      "55     versicolor\n",
      "132     virginica\n",
      "29         setosa\n",
      "127     virginica\n",
      "26         setosa\n",
      "128     virginica\n",
      "131     virginica\n",
      "145     virginica\n",
      "108     virginica\n",
      "143     virginica\n",
      "45         setosa\n",
      "30         setosa\n",
      "Name: species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score \n",
    "\n",
    "#select features and targets \n",
    "x=df.drop(['target','species'], axis=1)\n",
    "y=df['species']\n",
    "\n",
    "# Split the data into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#initialize the scalar \n",
    "scalar= StandardScaler() \n",
    "\n",
    "#Fit and transform the training data\n",
    "x_train_scaled = scalar.fit_transform(x_train)\n",
    "\n",
    "print(f'Scaled X_Train: {x_train_scaled}')\n",
    "\n",
    "#initialize the logistic Regression Model \n",
    "log_reg = LogisticRegression() \n",
    "\n",
    "#Fit the model\n",
    "log_reg.fit(x_train_scaled, y_train)    \n",
    "\n",
    "#Predict on the test data\n",
    "y_pred=log_reg.predict(x_train_scaled)\n",
    "\n",
    "print(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [30, 120]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m confusion_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfusion_matrix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#classification Report \u001b[39;00m\n",
      "File \u001b[1;32md:\\Hackademia_ML\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\Hackademia_ML\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    248\u001b[0m     {\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32md:\\Hackademia_ML\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Hackademia_ML\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [30, 120]"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix: {confusion_matrix}')\n",
    "\n",
    "#classification Report \n",
    "classification_report = classification_report(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
